{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # Import this\n",
    "\n",
    "# Load and preprocess data\n",
    "all_news = \"D:/Dataset/Fake_News_Dataset_Malayalam/mal_fake_train.csv\"\n",
    "\n",
    "all_df = pd.read_csv(all_news)\n",
    "\n",
    "true_df = all_df[all_df[\"label\"] == \"original\"]\n",
    "fake_df = all_df[all_df[\"label\"] == \"Fake\"]\n",
    "true_df.loc[:, \"label\"] = 1  # 1 for true news\n",
    "fake_df.loc[:, \"label\"] = 0  # 0 for fake news\n",
    "\n",
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=43).reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['text'], combined_df['label'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load mBERT model and tokenizer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model_bert \u001b[38;5;241m=\u001b[39m \u001b[43mBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-multilingual-cased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Tokenize and encode text\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbert_encode\u001b[39m(texts, tokenizer, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3852\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3843\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3844\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3845\u001b[0m     (\n\u001b[0;32m   3846\u001b[0m         model,\n\u001b[0;32m   3847\u001b[0m         missing_keys,\n\u001b[0;32m   3848\u001b[0m         unexpected_keys,\n\u001b[0;32m   3849\u001b[0m         mismatched_keys,\n\u001b[0;32m   3850\u001b[0m         offload_index,\n\u001b[0;32m   3851\u001b[0m         error_msgs,\n\u001b[1;32m-> 3852\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3859\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3860\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3863\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3864\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3868\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3870\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[0;32m   3871\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4227\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# Whole checkpoint\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     mismatched_keys \u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[0;32m   4220\u001b[0m         state_dict,\n\u001b[0;32m   4221\u001b[0m         model_state_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4225\u001b[0m         ignore_mismatched_sizes,\n\u001b[0;32m   4226\u001b[0m     )\n\u001b[1;32m-> 4227\u001b[0m     error_msgs \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4228\u001b[0m     offload_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4230\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n\u001b[0;32m   4231\u001b[0m \n\u001b[0;32m   4232\u001b[0m     \u001b[38;5;66;03m# This should always be a list but, just to be sure.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:629\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[1;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 629\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:627\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:627\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:623\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    621\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 623\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2040\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[0;32m   2039\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2040\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   2042\u001b[0m     error_msgs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhile copying the parameter named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2043\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the model are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2044\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the checkpoint are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_param\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2045\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124man exception occurred : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2046\u001b[0m                       )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load mBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Tokenize and encode text\n",
    "def bert_encode(texts, tokenizer, max_len=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',  # Updated to avoid the deprecation warning\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
    "\n",
    "X_train_bert, attention_masks_train = bert_encode(X_train, tokenizer)\n",
    "X_test_bert, attention_masks_test = bert_encode(X_test, tokenizer)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_train_bert = model_bert(X_train_bert, attention_mask=attention_masks_train)[0][:, 0, :]\n",
    "    X_test_bert = model_bert(X_test_bert, attention_mask=attention_masks_test)[0][:, 0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer for SVM\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "svm_pred = svm.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "41/41 [==============================] - 16s 257ms/step - loss: 0.6904 - accuracy: 0.5651 - val_loss: 0.6877 - val_accuracy: 0.5230\n",
      "Epoch 2/3\n",
      "41/41 [==============================] - 10s 243ms/step - loss: 0.6831 - accuracy: 0.5766 - val_loss: 0.6852 - val_accuracy: 0.5399\n",
      "Epoch 3/3\n",
      "41/41 [==============================] - 10s 243ms/step - loss: 0.6741 - accuracy: 0.6146 - val_loss: 0.6831 - val_accuracy: 0.5537\n",
      "21/21 [==============================] - 1s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and pad sequences for LSTM\n",
    "max_len = 128\n",
    "tokenizer_lstm = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_lstm.fit_on_texts(X_train)\n",
    "\n",
    "X_train_lstm = tokenizer_lstm.texts_to_sequences(X_train)\n",
    "X_test_lstm = tokenizer_lstm.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_lstm = pad_sequences(X_train_lstm, maxlen=max_len)\n",
    "X_test_lstm = pad_sequences(X_test_lstm, maxlen=max_len)\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(len(tokenizer_lstm.word_index) + 1, 128, input_length=max_len))\n",
    "lstm_model.add(SpatialDropout1D(0.2))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train LSTM\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=3, batch_size=64, validation_data=(X_test_lstm, y_test))\n",
    "lstm_pred = (lstm_model.predict(X_test_lstm) > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 1.0\n",
      "Confusion Matrix for Ensemble Classifier:\n",
      "[[326   0]\n",
      " [  0 326]]\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenate predictions\n",
    "X_test_features = np.column_stack([X_test_bert.numpy(), svm_pred, lstm_pred])\n",
    "\n",
    "# Train Gradient Boosting Classifier as the final model\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_test_features, y_test)\n",
    "\n",
    "# Get final predictions\n",
    "final_pred = gb.predict(X_test_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, final_pred)\n",
    "print(\"Final accuracy:\", accuracy)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix for Ensemble Classifier:\")\n",
    "print(confusion_matrix(y_test, final_pred))\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, final_pred, average='binary')\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
